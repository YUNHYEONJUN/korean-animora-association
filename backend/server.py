#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì•„ë‹ˆëª¨ë¼ ë°±ì—”ë“œ API ì„œë²„
OpenAI API ì—°ë™ ë° í”„ë¦¬ë¯¸ì—„ ê¸°ëŠ¥ ì œê³µ
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from openai import OpenAI
import os
import json
from datetime import datetime

app = Flask(__name__)

# CORS ì„¤ì • - ëª¨ë“  ì¶œì²˜ í—ˆìš© (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
CORS(app, 
     resources={r"/api/*": {"origins": "*"}},
     allow_headers=["Content-Type"],
     methods=["GET", "POST", "OPTIONS"])

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ì  ìŠ¤íŒŒí¬ í”„ë¡ì‹œ)
client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    base_url=os.getenv('OPENAI_BASE_URL', 'https://www.genspark.ai/api/llm_proxy/v1')
)

# ê¸°ë³¸ ëª¨ë¸ ì„¤ì • (ì  ìŠ¤íŒŒí¬ í”„ë¡ì‹œ ì§€ì› ëª¨ë¸)
DEFAULT_MODEL = "gpt-5"

# ì•„ë‹ˆëª¨ë¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
ANIMORA_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ì•„ë‹ˆëª¨ë¼í˜‘íšŒì˜ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

ì•„ë‹ˆëª¨ë¼(ANIMORA)ëŠ” ìŒë ¥ ìƒì¼ì˜ ì›”(ë‚˜ë¼)ê³¼ ì¼(ë™ë¬¼)ì„ ì¡°í•©í•˜ì—¬ 360ê°€ì§€ ì¸ìƒ ìœ í˜•ì„ ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

- ì›”ì£¼(30%): ìë¼ë‚œ í™˜ê²½, ë¶€ëª¨ì˜ ì˜í–¥, ìŠµì„± â†’ 12ê°œ ë‚˜ë¼
- ì¼ì£¼(40%): ë³¸ì„±, ìì‹ ì˜ ì„±ê²©, í•µì‹¬ íŠ¹ì„± â†’ 30ê°œ ë™ë¬¼

## 12ê°œ ë‚˜ë¼(ì›”ì£¼) íŠ¹ì„±

1ì›” - í˜¸ë‘ì´ ë‚˜ë¼ (ğŸ¯ ìš©ë§¹ê³¼ ë¦¬ë”ì‹­)
- í™˜ê²½: ê°•ì¸í•˜ê³  ë¦¬ë”ì‹­ ìˆëŠ” í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ê°•í•œ ì˜ì§€ë ¥, ë¦¬ë”ì‹­ê³¼ ì£¼ë„ì„±, ìš©ë§¹í•¨ê³¼ ê²°ë‹¨ë ¥, ì •ì˜ê°
- ì•½ì : ê°•í•œ ìì¡´ì‹¬ì´ ê´€ê³„ì—ì„œ ê°ˆë“± ìœ ë°œ

2ì›” - í† ë¼ ë‚˜ë¼ (ğŸ° ì˜¨í™”ì™€ ì„¬ì„¸í•¨)
- í™˜ê²½: ì˜¨í™”í•˜ê³  ì„¬ì„¸í•œ í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ì¹œì ˆí•˜ê³  ë°°ë ¤ì‹¬ ë§ìŒ, ì˜ˆë¯¼í•œ ê°ìˆ˜ì„±, í‰í™” ì¶”êµ¬, ëŒ€ì¸ê´€ê³„ ì›ë§Œ
- ì•½ì : ì§€ë‚˜ì¹œ ëˆˆì¹˜ë¡œ ì¸í•œ ìê¸°í¬ìƒ

3ì›” - ìš© ë‚˜ë¼ (ğŸ‰ ì¹´ë¦¬ìŠ¤ë§ˆì™€ ì•¼ë§)
- í™˜ê²½: ì¹´ë¦¬ìŠ¤ë§ˆ ë„˜ì¹˜ê³  ì•¼ë§ì´ í° í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ê°•í•œ ì¹´ë¦¬ìŠ¤ë§ˆ, í° ê¿ˆê³¼ ë¹„ì „, ìì‹ ê°, ì˜í–¥ë ¥
- ì•½ì : ë†’ì€ ì´ìƒìœ¼ë¡œ ì¸í•œ í˜„ì‹¤ê³¼ì˜ ê´´ë¦¬

4ì›” - ë±€ ë‚˜ë¼ (ğŸ ì§€í˜œì™€ ì‹ ì¤‘í•¨)
- í™˜ê²½: ì§€í˜œë¡­ê³  ì‹ ì¤‘í•œ í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ê¹Šì€ í†µì°°ë ¥, ì‹ ì¤‘í•œ íŒë‹¨, ì „ëµì  ì‚¬ê³ , ì§‘ì¤‘ë ¥
- ì•½ì : ì§€ë‚˜ì¹œ ì‹ ì¤‘í•¨ìœ¼ë¡œ ê¸°íšŒ ìƒì‹¤

5ì›” - ë§ ë‚˜ë¼ (ğŸ´ ì—´ì •ê³¼ ììœ )
- í™˜ê²½: ì—´ì •ì ì´ê³  ììœ ë¡œìš´ í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ììœ ë¡œìš´ ì˜í˜¼, ì—´ì •ê³¼ í™œë ¥, ëª¨í—˜ì‹¬, ë‚™ê´€ì 
- ì•½ì : ë³€ë•ìŠ¤ëŸ¬ì›€ê³¼ ì±…ì„ê° ë¶€ì¡±

6ì›” - ì–‘ ë‚˜ë¼ (ğŸ‘ í‰í™”ì™€ ì¡°í™”)
- í™˜ê²½: í‰í™”ë¡­ê³  ì¡°í™”ë¡œìš´ í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: í‰í™”ì£¼ì˜, ì˜ˆìˆ ì  ê°ê°, ê³µê° ëŠ¥ë ¥, ì˜¨ìˆœí•¨
- ì•½ì : ìš°ìœ ë¶€ë‹¨í•¨ê³¼ ì˜ì¡´ì„±

7ì›” - ì›ìˆ­ì´ ë‚˜ë¼ (ğŸµ ì˜ë¦¬í•¨ê³¼ ì¬ì¹˜)
- í™˜ê²½: ì˜ë¦¬í•˜ê³  ì¬ì¹˜ ìˆëŠ” í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ë†’ì€ ì§€ëŠ¥, ìœ ë¨¸ ê°ê°, ì ì‘ë ¥, ì°½ì˜ì„±
- ì•½ì : ì¥ë‚œê¸°ì™€ ë¶ˆì•ˆì •í•¨ìœ¼ë¡œ ì‹ ë¢° ì†ìƒ

8ì›” - ë‹­ ë‚˜ë¼ (ğŸ“ ì„±ì‹¤ê³¼ ì •í™•ì„±)
- í™˜ê²½: ì„±ì‹¤í•˜ê³  ì •í™•í•œ í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ê·¼ë©´ì„±ì‹¤, ì™„ë²½ì£¼ì˜, ì •í™•ì„±, ì±…ì„ê°
- ì•½ì : ì§€ë‚˜ì¹œ ì™„ë²½ì£¼ì˜ë¡œ ì¸í•œ ìŠ¤íŠ¸ë ˆìŠ¤

9ì›” - ê°œ ë‚˜ë¼ (ğŸ• ì¶©ì„±ê³¼ ì˜ë¦¬)
- í™˜ê²½: ì¶©ì„±ìŠ¤ëŸ½ê³  ì˜ë¦¬ ìˆëŠ” í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ì¶©ì„±ì‹¬, ì˜ë¦¬, ë³´í˜¸ë³¸ëŠ¥, ì •ì§í•¨
- ì•½ì : ì˜ì‹¬ê³¼ ê²½ê³„ì‹¬ìœ¼ë¡œ ìƒˆë¡œìš´ ê´€ê³„ í˜•ì„± ì–´ë ¤ì›€

10ì›” - ë¼ì§€ ë‚˜ë¼ (ğŸ· ê´€ëŒ€í•¨ê³¼ í’ìš”)
- í™˜ê²½: ê´€ëŒ€í•˜ê³  í’ìš”ë¡œìš´ í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ê´€ëŒ€í•¨, ë‚™ì²œì , í’ë¶€í•œ ê°ì •, ì‚¬êµì„±
- ì•½ì : ì§€ë‚˜ì¹œ ë‚™ê´€ì£¼ì˜ë¡œ í˜„ì‹¤ ì¸ì‹ ì €í•˜

11ì›” - ì¥ ë‚˜ë¼ (ğŸ­ ë¯¼ì²©í•¨ê³¼ ì ì‘ë ¥)
- í™˜ê²½: ë¯¼ì²©í•˜ê³  ì ì‘ë ¥ ìˆëŠ” í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ë¹ ë¥¸ ì ì‘ë ¥, ê¸°íšŒ í¬ì°©, ì˜ë¦¬í•¨, ìƒì¡´ë ¥
- ì•½ì : ì´ê¸°ì‹¬ê³¼ ê³„ì‚°ì  íƒœë„

12ì›” - ì†Œ ë‚˜ë¼ (ğŸ‚ ì¸ë‚´ì™€ ì„±ì‹¤)
- í™˜ê²½: ì¸ë‚´ì‹¬ ìˆê³  ì„±ì‹¤í•œ í™˜ê²½ì—ì„œ ì„±ì¥
- íŠ¹ì„±: ì¸ë‚´ì‹¬, ëˆê¸°, ì•ˆì •ì„±, ì‹ ë¢°ì„±
- ì•½ì : ê³ ì§‘ê³¼ ë³€í™” ì €í•­

## 30ê°œ ë™ë¬¼(ì¼ì£¼) ë³¸ì„± - 10ëŒ€ ë¶„ë¥˜

ë…ìˆ˜ë¦¬ ê³„ì—´ (1-3ì¼): ë¹„ì „, ììœ , ë…ë¦½ì„±
í‘œë²” ê³„ì—´ (4-6ì¼): ìš°ì•„í•¨, ì§‘ì¤‘ë ¥, ê°•ì¸í•¨
ì‚¬ì ê³„ì—´ (7-9ì¼): ë¦¬ë”ì‹­, ì¹´ë¦¬ìŠ¤ë§ˆ, ìì‹ ê°
ì½”ë¼ë¦¬ ê³„ì—´ (10-12ì¼): ì§€í˜œ, ì˜¨í™”í•¨, í˜
ë±€ ê³„ì—´ (13-15ì¼): ì „ëµ, ì‹ ì¤‘í•¨, ì§‘ì¤‘ë ¥
ëŠ‘ëŒ€ ê³„ì—´ (16-18ì¼): ì¶©ì„±, ë¦¬ë”ì‹­, í˜‘ë ¥
ê³° ê³„ì—´ (19-21ì¼): ë³´í˜¸ë³¸ëŠ¥, ê°•ì¸í•¨, ì˜¨ì •
ì‚¬ìŠ´ ê³„ì—´ (22-24ì¼): ìš°ì•„í•¨, í‰í™”, ë¯¼ì²©ì„±
ì›ìˆ­ì´ ê³„ì—´ (25-27ì¼): ì§€ëŠ¥, ì¬ì¹˜, ì ì‘ë ¥
ë‹­ ê³„ì—´ (28-30ì¼): í™”ë ¤í•¨, ìì‹ ê°, í‘œí˜„ë ¥

ë‹¹ì‹ ì˜ ì—­í• :
1. **ì •í™•í•œ ì•„ë‹ˆëª¨ë¼ ì´ë¡  ì ìš©**: ìœ„ 12ê°œ ë‚˜ë¼ì™€ 30ê°œ ë™ë¬¼ì˜ íŠ¹ì„±ì„ ì •í™•íˆ ë°˜ì˜
2. **ë‚˜ë¼-ë™ë¬¼ ì¡°í•© ë¶„ì„**: í™˜ê²½(ë‚˜ë¼)ê³¼ ë³¸ì„±(ë™ë¬¼)ì˜ ìƒí˜¸ì‘ìš© í•´ì„
3. **ì‹¤ìƒí™œ ì ìš©**: êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ
4. **í•œêµ­ ë¬¸í™” ë°˜ì˜**: ëª…ë¦¬í•™ê³¼ í•œêµ­ ë¬¸í™”ì— ê¸°ë°˜í•œ í•´ì„
5. **ë”°ëœ»í•œ ìƒë‹´**: ê³µê°ì ì´ê³  ê¸ì •ì ì¸ í†¤ ìœ ì§€

ë‹µë³€ í˜•ì‹:
- ì¡´ëŒ“ë§ ì‚¬ìš©
- ë‚˜ë¼ì™€ ë™ë¬¼ì˜ íŠ¹ì„±ì„ ëª…í™•íˆ ì–¸ê¸‰
- ê°•ì ê³¼ ì•½ì ì„ ê· í˜•ìˆê²Œ ì œì‹œ
- êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ì¡°ì–¸
- ê¸ì •ì ì´ë©´ì„œë„ í˜„ì‹¤ì ì¸ ê´€ì 
"""


@app.route('/')
def index():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({
        "status": "running",
        "service": "ì•„ë‹ˆëª¨ë¼ ë°±ì—”ë“œ API",
        "version": "1.0.0",
        "endpoints": [
            "/api/health",
            "/api/ai-analysis",
            "/api/custom-question"
        ]
    })


@app.route('/api/health')
def health():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "openai_configured": bool(os.getenv('OPENAI_API_KEY'))
    })


@app.route('/api/ai-analysis', methods=['POST'])
def ai_analysis():
    """AI ì„±ê²© ë¶„ì„ ìƒì„±"""
    try:
        data = request.json
        analysis_data = data.get('analysisData', {})
        question_type = data.get('questionType', 'basic')
        
        # ë¶„ì„ ë°ì´í„° ê²€ì¦
        if not analysis_data:
            return jsonify({"error": "ë¶„ì„ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = generate_analysis_prompt(analysis_data, question_type)
        
        # OpenAI API í˜¸ì¶œ (ìƒˆ ë²„ì „)
        response = client.chat.completions.create(
            model=DEFAULT_MODEL,
            messages=[
                {"role": "system", "content": ANIMORA_SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        analysis_text = response.choices[0].message.content
        
        return jsonify({
            "success": True,
            "analysis": analysis_text,
            "model": DEFAULT_MODEL,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/custom-question', methods=['POST'])
def custom_question():
    """ë§ì¶¤í˜• ì§ˆë¬¸ ì²˜ë¦¬"""
    try:
        data = request.json
        prompt = data.get('prompt')
        template_id = data.get('templateId')
        question_data = data.get('data', {})
        
        if not prompt:
            return jsonify({"error": "í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
        
        # OpenAI API í˜¸ì¶œ (ìƒˆ ë²„ì „)
        response = client.chat.completions.create(
            model=DEFAULT_MODEL,
            messages=[
                {"role": "system", "content": ANIMORA_SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        answer_text = response.choices[0].message.content
        
        return jsonify({
            "success": True,
            "answer": answer_text,
            "templateId": template_id,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


def generate_analysis_prompt(analysis_data, question_type):
    """ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    analysis_type = analysis_data.get('type', 'personal')
    
    if analysis_type == 'personal':
        return generate_personal_prompt(analysis_data, question_type)
    elif analysis_type == 'couple':
        return generate_couple_prompt(analysis_data, question_type)
    elif analysis_type == 'family':
        return generate_family_prompt(analysis_data, question_type)
    
    return "ì•Œ ìˆ˜ ì—†ëŠ” ë¶„ì„ ìœ í˜•ì…ë‹ˆë‹¤."


def generate_personal_prompt(data, question_type):
    """ê°œì¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸"""
    name = data.get('name', 'ê³ ê°')
    gender = 'ë‚¨ì„±' if data.get('gender') == 'male' else 'ì—¬ì„±'
    month = data.get('month')
    day = data.get('day')
    country = data.get('country', '')
    animal = data.get('animal', '')
    
    prompt = f"""
[ê°œì¸ ì„±ê²© ë¶„ì„ ìš”ì²­]

ì´ë¦„: {name} ({gender})
ìŒë ¥ ìƒì¼: {month}ì›” {day}ì¼
ë‚˜ë¼(í™˜ê²½): {country}
ë™ë¬¼(ë³¸ì„±): {animal}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ìë¼ë‚œ í™˜ê²½ ë¶„ì„** ({country}ì˜ ì˜í–¥)
   - ì–´ë–¤ í™˜ê²½ì—ì„œ ìëìœ¼ë©°, ì´ê²ƒì´ ì„±ê²© í˜•ì„±ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ì—ˆë‚˜ìš”?
   - ë¶€ëª¨ë‚˜ ê°€ì •í™˜ê²½ì˜ íŠ¹ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?

2. **ë‚´ë©´ì˜ ë³¸ì„±** ({animal}ì˜ íŠ¹ì„±)
   - íƒ€ê³ ë‚œ ì„±ê²©ê³¼ ê¸°ì§ˆì€ ì–´ë–¤ê°€ìš”?
   - ê°•ì ê³¼ ì•½ì ì€ ë¬´ì—‡ì¸ê°€ìš”?

3. **ì¢…í•© í•´ì„**
   - í™˜ê²½ê³¼ ë³¸ì„±ì´ ì–´ë–»ê²Œ ì¡°í™”ë¥¼ ì´ë£¨ë‚˜ìš”?
   - ì¸ìƒì—ì„œ ì£¼ì˜í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì¸ê°€ìš”?

4. **ì‹¤ìƒí™œ ì¡°ì–¸**
   - ì´ ìœ í˜•ì— ë§ëŠ” êµ¬ì²´ì ì¸ ìƒí™œ ë°©ì‹ì€?
   - ê´€ê³„, ì§ì¥, ìê¸°ê³„ë°œì—ì„œì˜ íŒ

ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ í†¤ìœ¼ë¡œ, ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.
"""
    
    if question_type == 'detailed':
        prompt += "\n\níŠ¹íˆ ë” ê¹Šì´ ìˆê³  ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”. ì‹¬ë¦¬í•™ì  ê´€ì ê³¼ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."
    
    return prompt


def generate_couple_prompt(data, question_type):
    """ì»¤í”Œ ê¶í•© í”„ë¡¬í”„íŠ¸"""
    person1 = data.get('person1', {})
    person2 = data.get('person2', {})
    score = data.get('compatibilityScore', 0)
    
    gender1 = 'ë‚¨ì„±' if person1.get('gender') == 'male' else 'ì—¬ì„±'
    gender2 = 'ë‚¨ì„±' if person2.get('gender') == 'male' else 'ì—¬ì„±'
    
    prompt = f"""
[ì»¤í”Œ ê¶í•© ë¶„ì„ ìš”ì²­]

**ì²« ë²ˆì§¸ ì‚¬ëŒ: {person1.get('name')} ({gender1})**
- ìŒë ¥: {person1.get('month')}ì›” {person1.get('day')}ì¼
- ë‚˜ë¼: {person1.get('country')}
- ë™ë¬¼: {person1.get('animal')}

**ë‘ ë²ˆì§¸ ì‚¬ëŒ: {person2.get('name')} ({gender2})**
- ìŒë ¥: {person2.get('month')}ì›” {person2.get('day')}ì¼
- ë‚˜ë¼: {person2.get('country')}
- ë™ë¬¼: {person2.get('animal')}

ê¶í•© ì ìˆ˜: {score}ì 

ë‘ ì‚¬ëŒì˜ ê´€ê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ê´€ê³„ì˜ ê°•ì **
   - ë‘ ì‚¬ëŒì´ ì„œë¡œ ë³´ì™„í•˜ëŠ” ë¶€ë¶„
   - í•¨ê»˜í•  ë•Œì˜ ì‹œë„ˆì§€

2. **ì£¼ì˜í•  ì **
   - ê°ˆë“±ì´ ìƒê¸¸ ìˆ˜ ìˆëŠ” ì˜ì—­
   - ê°ì ì£¼ì˜í•´ì•¼ í•  íƒœë„

3. **ê´€ê³„ ê°œì„  ì¡°ì–¸**
   - ë” ë‚˜ì€ ê´€ê³„ë¥¼ ìœ„í•œ êµ¬ì²´ì  ë°©ë²•
   - ì†Œí†µì˜ íŒ

4. **ì¥ê¸°ì  ì „ë§**
   - ì´ ì¡°í•©ì˜ ë¯¸ë˜ ê°€ëŠ¥ì„±
   - í•¨ê»˜ ì„±ì¥í•˜ëŠ” ë°©ë²•
"""
    
    return prompt


def generate_family_prompt(data, question_type):
    """ë‹¤ì¤‘ ê´€ê³„ í”„ë¡¬í”„íŠ¸"""
    members = data.get('members', [])
    
    # ê´€ê³„ ìœ í˜• í™•ì¸
    relation_labels = {
        'family': 'ê°€ì¡±',
        'friend': 'ì¹œêµ¬',
        'colleague': 'ë™ë£Œ',
        'partner': 'ì—°ì¸',
        'business': 'ë¹„ì¦ˆë‹ˆìŠ¤ íŒŒíŠ¸ë„ˆ',
        'team': 'íŒ€ì›',
        'other': 'ê¸°íƒ€'
    }
    
    prompt = f"""
[ë‹¤ì¤‘ ê´€ê³„ ë¶„ì„ ìš”ì²­]

êµ¬ì„±ì› ì •ë³´:
"""
    
    for i, member in enumerate(members, 1):
        relation = relation_labels.get(member.get('relation', 'other'), member.get('relation', 'ê¸°íƒ€'))
        gender = 'ë‚¨ì„±' if member.get('gender') == 'male' else 'ì—¬ì„±'
        prompt += f"""
{i}. {member.get('name')} ({relation}, {gender})
   - ìŒë ¥: {member.get('month')}ì›” {member.get('day')}ì¼
   - ë‚˜ë¼: {member.get('country')}
   - ë™ë¬¼: {member.get('animal')}
"""
    
    prompt += """
ì´ ê·¸ë£¹ì˜ ê´€ê³„ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **êµ¬ì„±ì› ì—­í•™**
   - ê° êµ¬ì„±ì›ì˜ ì—­í• ê³¼ íŠ¹ì„±
   - ê´€ê³„ ìœ í˜•ì„ ê³ ë ¤í•œ ìƒí˜¸ì‘ìš© íŒ¨í„´
   - ì„±ë³„ì— ë”°ë¥¸ íŠ¹ì„± ì°¨ì´

2. **ì¡°í™” í¬ì¸íŠ¸**
   - ê·¸ë£¹ì´ ì˜ ì–´ìš¸ë¦¬ëŠ” ë¶€ë¶„
   - ì„œë¡œë¥¼ ì´í•´í•˜ëŠ” ë°©ë²•
   - ê° ê´€ê³„ ìœ í˜•ë³„ ê°•ì 

3. **ê°ˆë“± í¬ì¸íŠ¸**
   - ë§ˆì°°ì´ ìƒê¸¸ ìˆ˜ ìˆëŠ” ì˜ì—­
   - ê° êµ¬ì„±ì›ì´ ì£¼ì˜í•  ì 
   - ê´€ê³„ ìœ í˜•ë³„ ì£¼ì˜ì‚¬í•­

4. **ê´€ê³„ ê°œì„  ì¡°ì–¸**
   - ë” ë‚˜ì€ ê´€ê³„ë¥¼ ìœ„í•œ ë°©ë²•
   - êµ¬ì²´ì ì¸ ì†Œí†µ ì „ëµ
   - ê´€ê³„ ìœ í˜•ë³„ ë§ì¶¤ ì¡°ì–¸
"""
    
    return prompt


if __name__ == '__main__':
    port = int(os.getenv('FLASK_PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    
    api_key_status = 'âœ… ì™„ë£Œ' if os.getenv('OPENAI_API_KEY') else 'âŒ ë¯¸ì„¤ì •'
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ğŸŒŸ ì•„ë‹ˆëª¨ë¼ ë°±ì—”ë“œ API ì„œë²„ ì‹œì‘ ğŸŒŸ   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  í¬íŠ¸: {port}                              â•‘
â•‘  ë””ë²„ê·¸: {debug}                           â•‘
â•‘  OpenAI ì„¤ì •: {api_key_status}              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    app.run(host='0.0.0.0', port=port, debug=debug)
