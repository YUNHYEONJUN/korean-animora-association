#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì•„ë‹ˆëª¨ë¼ ë°±ì—”ë“œ API ì„œë²„
OpenAI API ì—°ë™ ë° í”„ë¦¬ë¯¸ì—„ ê¸°ëŠ¥ ì œê³µ
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import openai
import os
import json
from datetime import datetime

app = Flask(__name__)

# CORS ì„¤ì • - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡
CORS(app, resources={
    r"/api/*": {
        "origins": [
            "http://localhost:8000",
            "http://localhost:8001",
            "https://*.sandbox.novita.ai",
            "https://yunhyeonjun.github.io"
        ]
    }
})

# OpenAI API ì„¤ì • (ì  ìŠ¤íŒŒí¬ í”„ë¡ì‹œ)
openai.api_key = os.getenv('OPENAI_API_KEY')
openai.api_base = os.getenv('OPENAI_BASE_URL', 'https://www.genspark.ai/api/llm_proxy/v1')

# ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
DEFAULT_MODEL = "gpt-4"

# ì•„ë‹ˆëª¨ë¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
ANIMORA_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ì•„ë‹ˆëª¨ë¼í˜‘íšŒì˜ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

ì•„ë‹ˆëª¨ë¼(ANIMORA)ëŠ” ìŒë ¥ ìƒì¼ì˜ ì›”(ë‚˜ë¼)ê³¼ ì¼(ë™ë¬¼)ì„ ì¡°í•©í•˜ì—¬ 360ê°€ì§€ ì¸ìƒ ìœ í˜•ì„ ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

- ì›”ì£¼(30%): ìë¼ë‚œ í™˜ê²½, ë¶€ëª¨ì˜ ì˜í–¥, ìŠµì„± â†’ 12ê°œ ë‚˜ë¼
- ì¼ì£¼(40%): ë³¸ì„±, ìì‹ ì˜ ì„±ê²©, í•µì‹¬ íŠ¹ì„± â†’ 30ê°œ ë™ë¬¼

ë‹¹ì‹ ì˜ ì—­í• :
1. ìŒë ¥ ìƒì¼ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¹Šì´ ìˆëŠ” ì„±ê²© ë¶„ì„ ì œê³µ
2. ì‹¤ìƒí™œì— ì ìš© ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì¡°ì–¸
3. í•œêµ­ ë¬¸í™”ì™€ ëª…ë¦¬í•™ì— ê¸°ë°˜í•œ í•´ì„
4. ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ìƒë‹´ í†¤

ë‹µë³€ í˜•ì‹:
- ì¡´ëŒ“ë§ ì‚¬ìš©
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸
- ê¸ì •ì ì´ë©´ì„œë„ í˜„ì‹¤ì ì¸ ê´€ì 
- 1000ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
"""


@app.route('/')
def index():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({
        "status": "running",
        "service": "ì•„ë‹ˆëª¨ë¼ ë°±ì—”ë“œ API",
        "version": "1.0.0",
        "endpoints": [
            "/api/health",
            "/api/ai-analysis",
            "/api/custom-question"
        ]
    })


@app.route('/api/health')
def health():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "openai_configured": bool(openai.api_key)
    })


@app.route('/api/ai-analysis', methods=['POST'])
def ai_analysis():
    """AI ì„±ê²© ë¶„ì„ ìƒì„±"""
    try:
        data = request.json
        analysis_data = data.get('analysisData', {})
        question_type = data.get('questionType', 'basic')
        
        # ë¶„ì„ ë°ì´í„° ê²€ì¦
        if not analysis_data:
            return jsonify({"error": "ë¶„ì„ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = generate_analysis_prompt(analysis_data, question_type)
        
        # OpenAI API í˜¸ì¶œ
        response = openai.ChatCompletion.create(
            model=DEFAULT_MODEL,
            messages=[
                {"role": "system", "content": ANIMORA_SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        analysis_text = response.choices[0].message.content
        
        return jsonify({
            "success": True,
            "analysis": analysis_text,
            "model": DEFAULT_MODEL,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/custom-question', methods=['POST'])
def custom_question():
    """ë§ì¶¤í˜• ì§ˆë¬¸ ì²˜ë¦¬"""
    try:
        data = request.json
        prompt = data.get('prompt')
        template_id = data.get('templateId')
        question_data = data.get('data', {})
        
        if not prompt:
            return jsonify({"error": "í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400
        
        # OpenAI API í˜¸ì¶œ
        response = openai.ChatCompletion.create(
            model=DEFAULT_MODEL,
            messages=[
                {"role": "system", "content": ANIMORA_SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        answer_text = response.choices[0].message.content
        
        return jsonify({
            "success": True,
            "answer": answer_text,
            "templateId": template_id,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


def generate_analysis_prompt(analysis_data, question_type):
    """ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    analysis_type = analysis_data.get('type', 'personal')
    
    if analysis_type == 'personal':
        return generate_personal_prompt(analysis_data, question_type)
    elif analysis_type == 'couple':
        return generate_couple_prompt(analysis_data, question_type)
    elif analysis_type == 'family':
        return generate_family_prompt(analysis_data, question_type)
    
    return "ì•Œ ìˆ˜ ì—†ëŠ” ë¶„ì„ ìœ í˜•ì…ë‹ˆë‹¤."


def generate_personal_prompt(data, question_type):
    """ê°œì¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸"""
    name = data.get('name', 'ê³ ê°')
    month = data.get('month')
    day = data.get('day')
    country = data.get('country', '')
    animal = data.get('animal', '')
    
    prompt = f"""
[ê°œì¸ ì„±ê²© ë¶„ì„ ìš”ì²­]

ì´ë¦„: {name}
ìŒë ¥ ìƒì¼: {month}ì›” {day}ì¼
ë‚˜ë¼(í™˜ê²½): {country}
ë™ë¬¼(ë³¸ì„±): {animal}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ìë¼ë‚œ í™˜ê²½ ë¶„ì„** ({country}ì˜ ì˜í–¥)
   - ì–´ë–¤ í™˜ê²½ì—ì„œ ìëìœ¼ë©°, ì´ê²ƒì´ ì„±ê²© í˜•ì„±ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ì—ˆë‚˜ìš”?
   - ë¶€ëª¨ë‚˜ ê°€ì •í™˜ê²½ì˜ íŠ¹ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?

2. **ë‚´ë©´ì˜ ë³¸ì„±** ({animal}ì˜ íŠ¹ì„±)
   - íƒ€ê³ ë‚œ ì„±ê²©ê³¼ ê¸°ì§ˆì€ ì–´ë–¤ê°€ìš”?
   - ê°•ì ê³¼ ì•½ì ì€ ë¬´ì—‡ì¸ê°€ìš”?

3. **ì¢…í•© í•´ì„**
   - í™˜ê²½ê³¼ ë³¸ì„±ì´ ì–´ë–»ê²Œ ì¡°í™”ë¥¼ ì´ë£¨ë‚˜ìš”?
   - ì¸ìƒì—ì„œ ì£¼ì˜í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì¸ê°€ìš”?

4. **ì‹¤ìƒí™œ ì¡°ì–¸**
   - ì´ ìœ í˜•ì— ë§ëŠ” êµ¬ì²´ì ì¸ ìƒí™œ ë°©ì‹ì€?
   - ê´€ê³„, ì§ì¥, ìê¸°ê³„ë°œì—ì„œì˜ íŒ

ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ í†¤ìœ¼ë¡œ, ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.
"""
    
    if question_type == 'detailed':
        prompt += "\n\níŠ¹íˆ ë” ê¹Šì´ ìˆê³  ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”. ì‹¬ë¦¬í•™ì  ê´€ì ê³¼ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."
    
    return prompt


def generate_couple_prompt(data, question_type):
    """ì»¤í”Œ ê¶í•© í”„ë¡¬í”„íŠ¸"""
    person1 = data.get('person1', {})
    person2 = data.get('person2', {})
    score = data.get('compatibilityScore', 0)
    
    prompt = f"""
[ì»¤í”Œ ê¶í•© ë¶„ì„ ìš”ì²­]

**ì²« ë²ˆì§¸ ì‚¬ëŒ: {person1.get('name')}**
- ìŒë ¥: {person1.get('month')}ì›” {person1.get('day')}ì¼
- ë‚˜ë¼: {person1.get('country')}
- ë™ë¬¼: {person1.get('animal')}

**ë‘ ë²ˆì§¸ ì‚¬ëŒ: {person2.get('name')}**
- ìŒë ¥: {person2.get('month')}ì›” {person2.get('day')}ì¼
- ë‚˜ë¼: {person2.get('country')}
- ë™ë¬¼: {person2.get('animal')}

ê¶í•© ì ìˆ˜: {score}ì 

ë‘ ì‚¬ëŒì˜ ê´€ê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ê´€ê³„ì˜ ê°•ì **
   - ë‘ ì‚¬ëŒì´ ì„œë¡œ ë³´ì™„í•˜ëŠ” ë¶€ë¶„
   - í•¨ê»˜í•  ë•Œì˜ ì‹œë„ˆì§€

2. **ì£¼ì˜í•  ì **
   - ê°ˆë“±ì´ ìƒê¸¸ ìˆ˜ ìˆëŠ” ì˜ì—­
   - ê°ì ì£¼ì˜í•´ì•¼ í•  íƒœë„

3. **ê´€ê³„ ê°œì„  ì¡°ì–¸**
   - ë” ë‚˜ì€ ê´€ê³„ë¥¼ ìœ„í•œ êµ¬ì²´ì  ë°©ë²•
   - ì†Œí†µì˜ íŒ

4. **ì¥ê¸°ì  ì „ë§**
   - ì´ ì¡°í•©ì˜ ë¯¸ë˜ ê°€ëŠ¥ì„±
   - í•¨ê»˜ ì„±ì¥í•˜ëŠ” ë°©ë²•
"""
    
    return prompt


def generate_family_prompt(data, question_type):
    """ê°€ì¡± ê´€ê³„ í”„ë¡¬í”„íŠ¸"""
    members = data.get('members', [])
    
    prompt = f"""
[ê°€ì¡± ê´€ê³„ ë¶„ì„ ìš”ì²­]

ê°€ì¡± êµ¬ì„±ì›:
"""
    
    for i, member in enumerate(members, 1):
        prompt += f"""
{i}. {member.get('name')}
   - ìŒë ¥: {member.get('month')}ì›” {member.get('day')}ì¼
   - ë‚˜ë¼: {member.get('country')}
   - ë™ë¬¼: {member.get('animal')}
"""
    
    prompt += """
ê°€ì¡± ê´€ê³„ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ê°€ì¡± ì—­í•™**
   - ê° êµ¬ì„±ì›ì˜ ì—­í• ê³¼ íŠ¹ì„±
   - ê°€ì¡± ë‚´ ìƒí˜¸ì‘ìš© íŒ¨í„´

2. **ì¡°í™” í¬ì¸íŠ¸**
   - ê°€ì¡±ì´ ì˜ ì–´ìš¸ë¦¬ëŠ” ë¶€ë¶„
   - ì„œë¡œë¥¼ ì´í•´í•˜ëŠ” ë°©ë²•

3. **ê°ˆë“± í¬ì¸íŠ¸**
   - ë§ˆì°°ì´ ìƒê¸¸ ìˆ˜ ìˆëŠ” ì˜ì—­
   - ê° êµ¬ì„±ì›ì´ ì£¼ì˜í•  ì 

4. **ê°€ì¡± í™”í•© ì¡°ì–¸**
   - ë” ë‚˜ì€ ê°€ì¡± ê´€ê³„ë¥¼ ìœ„í•œ ë°©ë²•
   - êµ¬ì²´ì ì¸ ì†Œí†µ ì „ëµ
"""
    
    return prompt


if __name__ == '__main__':
    port = int(os.getenv('FLASK_PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ğŸŒŸ ì•„ë‹ˆëª¨ë¼ ë°±ì—”ë“œ API ì„œë²„ ì‹œì‘ ğŸŒŸ   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  í¬íŠ¸: {port}                              â•‘
â•‘  ë””ë²„ê·¸: {debug}                           â•‘
â•‘  OpenAI ì„¤ì •: {'âœ… ì™„ë£Œ' if openai.api_key else 'âŒ ë¯¸ì„¤ì •'}              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    app.run(host='0.0.0.0', port=port, debug=debug)
